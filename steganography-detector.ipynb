{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4043617,"sourceType":"datasetVersion","datasetId":2395063,"isSourceIdPinned":false}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:27:52.622321Z","iopub.execute_input":"2025-07-01T18:27:52.622540Z","iopub.status.idle":"2025-07-01T18:27:54.426752Z","shell.execute_reply.started":"2025-07-01T18:27:52.622512Z","shell.execute_reply":"2025-07-01T18:27:54.426029Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Steganalysis Project: Detecting Hidden Data in Images\n\nThis project aims to build a Convolutional Neural Network (CNN) based machine learning model to detect steganographic data hidden within images, and then deploy this model via a Streamlit web application.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np\nimport os\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:27:54.428019Z","iopub.execute_input":"2025-07-01T18:27:54.428414Z","iopub.status.idle":"2025-07-01T18:28:08.293556Z","shell.execute_reply.started":"2025-07-01T18:27:54.428377Z","shell.execute_reply":"2025-07-01T18:28:08.292789Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Dataset\n**Stego-Images-Dataset**\n44,000 images containing malicious JS, HTML, PS, URL, ethereum embedded via LSB\n.\n**Dataset Link**: https://www.kaggle.com/datasets/marcozuppelli/stegoimagesdataset/data","metadata":{}},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"marcozuppelli/stegoimagesdataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:28:08.294272Z","iopub.execute_input":"2025-07-01T18:28:08.294640Z","iopub.status.idle":"2025-07-01T18:28:10.455421Z","shell.execute_reply.started":"2025-07-01T18:28:08.294623Z","shell.execute_reply":"2025-07-01T18:28:10.454687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DATASET_PATH = '/kaggle/input/stegoimagesdataset'\nIMAGE_SIZE = (128, 128) # Standardize image size for the CNN\nBATCH_SIZE = 32\nEPOCHS = 100 # You might need to adjust this based on your training\nLEARNING_RATE = 0.001\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:28:10.457063Z","iopub.execute_input":"2025-07-01T18:28:10.457267Z","iopub.status.idle":"2025-07-01T18:28:10.461059Z","shell.execute_reply.started":"2025-07-01T18:28:10.457250Z","shell.execute_reply":"2025-07-01T18:28:10.460286Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data Loading and Preprocessing Functions\n\nThese functions handle loading images from the specified directories, resizing them, converting them to RGB format, and normalizing pixel values. The `create_dataset_from_structured_directory` function is designed to read from the `train`, `val`, and `test` subdirectories.\n","metadata":{}},{"cell_type":"code","source":"def load_and_preprocess_image(image_path, target_size=IMAGE_SIZE):\n    \"\"\"\n    Loads an image, converts it to RGB, resizes it, and normalizes pixel values.\n    \"\"\"\n    try:\n        img = Image.open(image_path).convert('RGB')\n        img = img.resize(target_size)\n        img_array = np.array(img)\n        # Normalize pixel values to [0, 1]\n        img_array = img_array.astype('float32') / 255.0\n        return img_array\n    except Exception as e:\n        print(f\"Error loading image {image_path}: {e}\")\n        return None\n\ndef create_dataset_from_structured_directory(dataset_root, image_size=IMAGE_SIZE):\n    \"\"\"\n    Loads images from 'clean' (cover) and 'stego' subdirectories within\n    'train', 'val', and 'test' folders, accounting for the nested structure.\n    Returns numpy arrays for images and labels for each split.\n    \"\"\"\n    splits = ['train', 'val', 'test']\n    datasets = {}\n\n    for split in splits:\n        # Adjusted path to account for the extra nested directory (e.g., train/train)\n        split_path = os.path.join(dataset_root, split, split) # <--- THIS LINE WAS CHANGED\n        clean_path = os.path.join(split_path, 'clean')\n        stego_path = os.path.join(split_path, 'stego')\n\n        all_images = []\n        all_labels = [] # 0 for clean (cover), 1 for stego\n\n        print(f\"Loading {split} clean images from: {clean_path}\")\n        if os.path.exists(clean_path):\n            for filename in os.listdir(clean_path):\n                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n                    img_path = os.path.join(clean_path, filename)\n                    img = load_and_preprocess_image(img_path, image_size)\n                    if img is not None:\n                        all_images.append(img)\n                        all_labels.append(0) # Label 0 for clean/cover\n        else:\n            print(f\"Warning: Clean directory not found for {split} at {clean_path}\")\n\n        print(f\"Loading {split} stego images from: {stego_path}\")\n        if os.path.exists(stego_path):\n            for filename in os.listdir(stego_path):\n                if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n                    img_path = os.path.join(stego_path, filename)\n                    img = load_and_preprocess_image(img_path, image_size)\n                    if img is not None:\n                        all_images.append(img)\n                        all_labels.append(1) # Label 1 for stego\n        else:\n            print(f\"Warning: Stego directory not found for {split} at {stego_path}\")\n\n        if not all_images:\n            print(f\"No images found for {split} split. Skipping this split.\")\n            datasets[split] = (None, None)\n            continue\n\n        X = np.array(all_images)\n        y = np.array(all_labels)\n\n        # Shuffle the dataset for the current split\n        indices = np.arange(len(X))\n        np.random.shuffle(indices)\n        X = X[indices]\n        y = y[indices]\n\n        print(f\"Loaded {len(X)} images for {split} split. {np.sum(y == 0)} clean, {np.sum(y == 1)} stego.\")\n        datasets[split] = (X, y)\n\n    return datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:28:10.461832Z","iopub.execute_input":"2025-07-01T18:28:10.462087Z","iopub.status.idle":"2025-07-01T18:28:10.480361Z","shell.execute_reply.started":"2025-07-01T18:28:10.462065Z","shell.execute_reply":"2025-07-01T18:28:10.479704Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### CNN Model Definition\n\nThis section defines the Convolutional Neural Network (CNN) architecture. The model includes multiple convolutional layers, batch normalization, max pooling, and dropout layers to effectively learn features for steganalysis. The final layer uses a sigmoid activation for binary classification (stego vs. non-stego).\n\n","metadata":{}},{"cell_type":"code","source":"def create_steganalysis_cnn_model(input_shape=IMAGE_SIZE + (3,)):\n    \"\"\"\n    Defines a CNN model architecture suitable for steganalysis.\n    This model incorporates concepts like high-pass filtering (implicitly\n    learned by initial layers), residual connections, and batch normalization.\n    \"\"\"\n    model = models.Sequential([\n        # Initial layers to learn high-pass filter-like features\n        layers.Conv2D(32, (5, 5), activation='relu', padding='same', input_shape=input_shape),\n        layers.BatchNormalization(),\n        layers.Conv2D(32, (5, 5), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n        layers.Dropout(0.25),\n\n        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n        layers.Dropout(0.25),\n\n        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n        layers.BatchNormalization(),\n        layers.MaxPooling2D((2, 2)),\n        layers.Dropout(0.25),\n\n        layers.Flatten(),\n        layers.Dense(256, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.5),\n        layers.Dense(1, activation='sigmoid') # Binary classification: stego or not\n    ])\n\n    # Compile the model\n    model.compile(optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:28:10.480972Z","iopub.execute_input":"2025-07-01T18:28:10.481140Z","iopub.status.idle":"2025-07-01T18:28:10.506564Z","shell.execute_reply.started":"2025-07-01T18:28:10.481127Z","shell.execute_reply":"2025-07-01T18:28:10.506078Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Load Data, Create Model, and Train\n\nThis section demonstrates how to load the dataset using the defined functions, create an instance of the CNN model, and then train it using the training and validation data. Finally, the model is evaluated on the test set and saved.","metadata":{}},{"cell_type":"code","source":"# Load and preprocess data from structured directories\ndatasets = create_dataset_from_structured_directory(DATASET_PATH)\n\nX_train, y_train = datasets.get('train', (None, None))\nX_val, y_val = datasets.get('val', (None, None))\nX_test, y_test = datasets.get('test', (None, None))\n\nif X_train is not None and y_train is not None:\n    print(f\"X_train shape: {X_train.shape}\")\n    print(f\"y_train shape: {y_train.shape}\")\nif X_val is not None and y_val is not None:\n    print(f\"X_val shape: {X_val.shape}\")\n    print(f\"y_val shape: {y_val.shape}\")\nif X_test is not None and y_test is not None:\n    print(f\"X_test shape: {X_test.shape}\")\n    print(f\"y_test shape: {y_test.shape}\")\n\nif X_train is not None and y_train is not None and X_val is not None and y_val is not None:\n    # Create the CNN model\n    model = create_steganalysis_cnn_model()\n    model.summary()\n\n    # Train the model\n    print(\"\\n--- Starting Model Training ---\")\n    history = model.fit(X_train, y_train,\n                        epochs=EPOCHS,\n                        batch_size=BATCH_SIZE,\n                        validation_data=(X_val, y_val)) # Use validation set for validation\n\n    print(\"\\n--- Model Training Complete ---\")\n\n    # Evaluate the model on the test set if available\n    if X_test is not None and y_test is not None:\n        loss, accuracy = model.evaluate(X_test, y_test)\n        print(f\"Test Loss: {loss:.4f}\")\n        print(f\"Test Accuracy: {accuracy:.4f}\")\n    else:\n        print(\"Test set not available for evaluation.\")\n\n    # Save the trained model\n    MODEL_SAVE_PATH = 'steganalysis_cnn_model.h5'\n    model.save(MODEL_SAVE_PATH)\n    print(f\"Model saved to {MODEL_SAVE_PATH}\")\nelse:\n    print(\"Required training or validation data not loaded. Cannot proceed with model training.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T18:28:10.507196Z","iopub.execute_input":"2025-07-01T18:28:10.507364Z","iopub.status.idle":"2025-07-01T19:05:43.485609Z","shell.execute_reply.started":"2025-07-01T18:28:10.507351Z","shell.execute_reply":"2025-07-01T19:05:43.484876Z"}},"outputs":[],"execution_count":null}]}